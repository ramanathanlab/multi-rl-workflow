"""Functions for training and rollout for a reinforcement learning model"""
from hashlib import sha512
from pathlib import Path
from random import random
import logging

from multirl.models import Sequence
from multirl.utils import get_hosts

logger = logging.getLogger(__name__)


class Model(float):
    """Placeholder class representing the RL model"""


# Globals used for warmable functions
loaded_model_path: Path | None = None  # Path to the model which is loaded
loaded_model: Model | None = None  # A loaded model


def train_model(model_path: Path, database: Path, num_workers: int,
                redis_info: tuple[str, int] = ('localhost', 6379)) -> tuple[Path, int, list[str]]:
    """Train a machine learning model cooperative with other workers

    Multiple instances of this function must be run across multiple workers.

    Args:
        model_path: Path to the current model
        database: Path to the training data
        num_workers: Number of cooperative workers to wait for
        redis_info: (Hostname, Port) for the redis server used to coordinate with other workers
    Returns:
        - Path to the new model
        - My rank within the hosts used for training
        - List of the hosts used for the computation
    """

    # Get all cooperative hosts
    key = sha512(str(model_path).encode()).hexdigest()[:16]
    my_rank, hosts = get_hosts(key, num_workers, redis_info)
    logger.info(f'Received list of {len(hosts)} hosts that will cooperate in model training')

    # Do the magic
    # Popen(f'python /do/all/the/train.py {model_path} {":".join(hosts)}')  # Example 1: Call out to a subprocess
    #
    # data = read(database)  # Example 2: run_locally
    # model = torch.load(model)
    # for epoch in range(128):
    #     get_rewards = ...
    #     loss = ...
    #     model.update(loss)
    # model.save(new_path)
    # return new_path, hosts
    return model_path, my_rank, hosts


def policy_rollout(model_path: Path, num_episodes: int, batch_size: int) -> list[Sequence]:
    """Generate a new batch of sequences given a policy

    Args:
        model_path: Path to the model being used to generate sequences
        num_episodes: Number of episodes over which to generate sequences
        batch_size: Number of sequences to generate at once
    Returns:
        Sequences generated by the model
    """
    global loaded_model
    global loaded_model_path

    # Load the model if it is new
    if loaded_model_path != model_path:
        from time import sleep
        sleep(0.5)
        loaded_model = model_path
        loaded_model_path = model_path

    # Generate sequences
    output = [
        sha512(str(random()).encode()).hexdigest()[:64]
        for _ in range(num_episodes * batch_size)
    ]

    return output
